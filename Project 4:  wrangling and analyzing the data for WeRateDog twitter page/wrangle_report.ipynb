{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project 4 : Wrangeling the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "Through this project our main focus was to wrangle the data which consisted of many steps Gathering,Assessing, and cleaning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gathering \n",
    "\n",
    "which is the most important step due that we here has collect the required data to extract the desired insights , we gathered the data in multiple ways \n",
    "\n",
    ">•\tDownloading the TSV file (‘image-predictions.tsv’) programmatically then load it into data frame\n",
    "<br>\n",
    ">•\tUploading the twitter-archive-enhanced.csv file manually through the notebook page\n",
    "<br>\n",
    ">•\tLoading the tweet_json.text to a data frame\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assessing \n",
    "\n",
    "this step comes after gathering all the needed data and its done by two ways visually and programmatically which we focus on seeing what needs to be proccessd before analyzing and extracting insights.after this I concluded the below issues that need to be taken care of:\n",
    "\n",
    "\n",
    "#### Quality issues\n",
    "\n",
    "1.change the type of timestamp to be datetime, through this step we need to assgin the correct type for this column which will ease any steps that can be done through this column\n",
    "\n",
    "2.remove unwanted columns and the ones that does have alot of null values,in this step it is better to delete which will make querying the columns more faster also for the columns that has alot of null values these are useless so it is better to get ride of them \n",
    "\n",
    "3.convert a and an to none instead in name column as we can see from our inspection there is around 70 entries that needs to be converted \n",
    "\n",
    "4.change columns name in df_images>\n",
    ">'p1':'prediction_of_golden_retriever',\n",
    ">'p1_conf':'prediction_confident_1',\n",
    ">'p1_dog':'result_for_prediction_1',\n",
    ">'p2':'prediction_of_Labrador_retriever',\n",
    ">'p2_conf':'prediction_confident_2'\n",
    "                            \n",
    "5.seperate date and time into two columns which will help us in aggregating date or time alone when required to analyze the data \n",
    "\n",
    "#### Tideness\n",
    "\n",
    "1.dog calssifications must be one column with three variables doggo, floofer, pupper, puppo columns into one column \n",
    "\n",
    "2.Combine three different dataframes into one master data set\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning \n",
    "\n",
    "for the cleaning part I used numpy and panda libraries for shaping the data "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
